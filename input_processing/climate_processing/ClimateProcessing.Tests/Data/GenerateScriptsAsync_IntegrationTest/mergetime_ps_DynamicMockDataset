#!/usr/bin/env bash
#PBS -N mergetime_ps_DynamicMockDataset
#PBS -o @#OUTPUT_DIRECTORY#@/logs/mergetime_ps_DynamicMockDataset.log
#PBS -P test
#PBS -q normal
#PBS -l walltime=06:30:00
#PBS -l ncpus=1
#PBS -l mem=4GB
#PBS -l jobfs=128GB
#PBS -j oe
#PBS -M test@example.com
#PBS -m abe

# This script was automatically generated. Do not modify.

# Exit immediately if any command fails.
set -euo pipefail

# Load required modules.
module purge
module load pbs netcdf cdo nco python3/3.12.1

# Create temporary directory and cd into it.
WORK_DIR="$(mktemp -d -p "${PBS_JOBFS}")"
cd "${WORK_DIR}"

# Delete the temporary directory on exit.
trap 'cd "${PBS_JOBFS}"; rm -rf "${WORK_DIR}"' EXIT

# Stream all output to a log file without buffering.
STREAM_FILE="@#OUTPUT_DIRECTORY#@/streams/mergetime_ps_DynamicMockDataset.log"
rm -f "${STREAM_FILE}"
exec 1> >(tee -a "${STREAM_FILE}") 2>&1

# Print a log message.
log() {
    echo "[$(date)] $*"
}

# File paths.
IN_DIR="/input/SurfacePressure"
REMAP_DIR="${WORK_DIR}/remap"
OUT_FILE="@#OUTPUT_DIRECTORY#@/tmp/dynamic_mock/ps_output.nc"
GRID_FILE="/home/giraffe/grid.nc"

mkdir -p "${REMAP_DIR}"

# Perform corrective operations on input files:
# - Remap input files to target grid.
# - Unpack data.
# - Aggregate data from 1hour to 3hour.
for FILE in "${IN_DIR}"/*.nc
do
    cdo -L -O -v -z zip1 -timselmean,3 -unpack -remapbil,"${GRID_FILE}" "${FILE}" "${REMAP_DIR}/$(basename "${FILE}")"
done
IN_DIR="${REMAP_DIR}"

log "Merging files..."
cdo -L -O -v -z zip1 mergetime "${IN_DIR}"/*.nc "${OUT_FILE}"
log "All files merged successfully."

