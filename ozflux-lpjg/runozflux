#!/usr/bin/env python
#
# A script to run ozflux site-level simulations in LPJ-Guess.
#

import traceback
import ozflux_common, ozflux_parallel
import subprocess, shutil

from argparse import ArgumentParser
from subprocess import PIPE, STDOUT
from ozflux_logging import *
from ozflux_netcdf import *
from sys import argv
from typing import Callable
from ozflux_parallel import JobManager

# Regular expression matching progress messages from LPJ-Guess.
_PROGRESS_REGEX = r"[^\d]+(\d+)% complete.*"

# Regular expression which matches the output directory in an instruction file.
_OUTDIR_REGEX = r"[ \t]*outputdirectory[ \t]+\"([^\"]+)\".*"

# Regular expression matching an enabled output file.
_OUTFILE_REGEX = r"[ \t]*file_[^\"]+\"([^\"]+)\".*"

# Regular expression matching 
_MET_FILE_PARAM = "file_met_forcing"

# Name of the ozflux outputs instruction file.
_OUTPUTS_INS = "outputs.ins"

_ALL_SITES = [
	"AdelaideRiver",
	"AliceSpringsMulga",
	"Boyagin",
	"Calperum",
	"CapeTribulation",
	"Collie",
	"CowBay",
	"CumberlandPlain",
	"DalyPasture",
	"DalyUncleared",
	"DryRiver",
	"Emerald",
	"FoggDam",
	"Gingin",
	"GreatWesternWoodlands",
	"HowardSprings",
	"Litchfield",
	"Longreach",
	"Otway",
	"RedDirtMelonFarm",
	"Ridgefield",
	"RiggsCreek",
	"RobsonCreek",
	"Samford",
	"SilverPlains",
	"SturtPlains",
	"TiTreeEast",
	"Tumbarumba",
	"WallabyCreek",
	"Warra",
	"Whroo",
	"WombatStateForest",
	"Yanco"
]

class Options:
	"""
	Class for storing CLI arguments from the user.

	@param log: Log level.
	@param files: Input files.
	@param out: Output file.
	@param prog: True to write progress messages, 0 otherwise.
	@param parallel: Number of simulations to run in parallel.
	@param repos: Path to one or more lpj-guess repositories.
	@param no_build: If true, the model will not be built before being run.
	@param no_run: If true, the model will not be run (only outputs copied).
	@param no_copy: If true, outputs will not be copied.
	"""
	def __init__(self, log : LogLevel, sites: list[str], out: str, prog: bool,
		parallel: int, repos: list[str], no_build: bool, no_run: bool,
		no_copy: bool):
		self.log_level = log
		self.sites = sites
		self.out_dir = out
		self.report_progress = prog
		self.parallel = parallel
		self.repos = repos
		self.build = not no_build
		self.run = not no_run
		self.copy = not no_copy

class SiteRunner(ozflux_parallel.Task):
	def __init__(self, ins_file: str, guess: str):
		self.ins_file = ins_file
		self.guess_path = guess

	def exec(self, pcb: Callable[[float], None]):
		log_diagnostic(f"Running {self.ins_file}...")
		ins = self.ins_file
		cmd = [self.guess_path, "-input", "nc", ins]
		wd = os.path.dirname(self.ins_file)
		run_proc(cmd, wd, lambda: log_error("Failed log run '%s'" % ins))
		proc = subprocess.Popen(cmd, cwd = wd, encoding = "utf-8", stdout = PIPE
			, stderr = STDOUT)
		pattern = re.compile(_PROGRESS_REGEX)
		while proc.poll() is None:
			msg = proc.stdout.readline()
			match = re.match(pattern, msg)
			if match is not None:
				percent_str = match.group(1)
				progress = float(percent_str) / 100
				pcb(progress)

		if proc.returncode != 0:
			site = os.path.basename(ins)
			m = "Error in %s: %s"
			raise subprocess.CalledProcessError(m % (site, proc.stdout))

class GuessBuilder(ozflux_parallel.Task):
	def __init__(self, repo: str):
		self.repo = repo
	def run(self, cmd: list[str], cwd: str):
		run_proc(cmd, cwd, lambda: log_error("Failed to build '%s'" % self.repo))
	def exec(self, pcb: Callable[[float], None]):
		log_diagnostic("Building %s..." % self.repo)
		BUILDDIR = "build"
		self.run([
			"cmake",
			"-DCMAKE_BUILD_TYPE=Release",
			"-DCMAKE_CXX_STANDARD=14",
			"-DCMAKE_CXX_STANDARD_REQUIRED=ON",
			"-DCMAKE_CXX_EXTENSIONS=ON",
			"-B",
			BUILDDIR
		], cwd = self.repo)
		self.run(["cmake", "--build", BUILDDIR, "-j", str(opts.parallel)], self.repo)

def run_proc(cmd: list[str], cwd: str, err_callback: Callable):
	res = subprocess.run(cmd, cwd = cwd, encoding = "utf-8", stdout = PIPE
		, stderr = STDOUT)
	if res.returncode != 0:
		try:
			err_callback()
		except BaseException as error:
			log_error("Error handlin routine threw an error")
			log_error(traceback.format_exc())
		log_error(res.stdout)
		res.check_returncode()

def parse_args(argv: list[str]) -> Options:
	"""
	Parse CLI arguments, return a parsed options object.

	@param argv: Raw CLI arguments.

	@return Parsed Options object.
	"""
	parser = ArgumentParser(prog=argv[0], description = "Run ozflux site-level simulations in LPJ-Guess")
	parser.add_argument("-v", "--verbosity", type = int, help = "Logging verbosity (1-5, default 3)", nargs = "?", const = LogLevel.INFORMATION, default = LogLevel.INFORMATION)
	parser.add_argument("-o", "--out-dir", help = "Path to desired output directory.")
	parser.add_argument("-p", "--show-progress", action = "store_true", help = "Report progress")
	parser.add_argument("-P", "--max-parallel", default = multiprocessing.cpu_count(), type = int, help = "Max number of simulations to run in parallel. Defaults to number of available processors.")
	parser.add_argument("-r", "--repository", action = "append", help = "Path to one or more lpj-guess repositories (use one -r/--repository option per repository)")
	parser.add_argument("-b", "--no-build", action = "store_true", help = "Don't build the model before running")
	parser.add_argument("--no-run", action = "store_true", help = "Don't run the model (ie only copy outputs)")
	parser.add_argument("--no-copy", action = "store_true", help = "Don't copy model outputs")
	parser.add_argument("--version", action = "version", version = "%(prog)s " + ozflux_common.VERSION)

	g = parser.add_mutually_exclusive_group()
	g.add_argument("-s", "--site", action = "append", help = "Specify one or more sites to run (use one -s/--site option per site)")
	g.add_argument("-a", "--all-sites", action = "store_true", help = "Run all sites")

	p = parser.parse_args(argv[1:])

	sites = _ALL_SITES if p.all_sites else p.site

	return Options(p.verbosity, sites, p.out_dir, p.show_progress
			, p.max_parallel, p.repository, p.no_build, p.no_run, p.no_copy)

def string_parameter_regex(param: str) -> str:
	"""
	Return a regular expression which matches a global string parameter in an
	LPJ-Guess instruction file. The regex contains 3 groups:

	1. Everything before the parameter value
	2. The parameter value
	3. Everything after the parameter value.
	"""
	rx = fr"([ \t]*{param}[ \t]*\")([^\"]+)(\".*)"
	return rx

def get_guess(repo: str) -> str:
	"""
	Get the lpj-guess path for the specified repository.
	"""
	guess = os.path.join(repo, "build", "guess")
	if os.name == "nt":
		guess += ".exe"
	return guess

def get_site_met(repo: str, site: str) -> str:
	"""
	Get the path to the met data file used for the specified site.

	@param repo: Path to the lpj-guess repository.
	@param site: Name of an ozflux site.
	"""
	site_path = get_site_path(repo, site)
	ins = get_site_ins(repo, site)
	pattern = re.compile(string_parameter_regex(_MET_FILE_PARAM))
	with open(ins, "r") as file:
		for line in file:
			match = re.match(pattern, line)
			if match is not None:
				met_path = match.group(2)
				if not os.path.isabs(met_path):
					joined = os.path.join(site_path, met_path)
					met_path = os.path.normpath(joined)
				return met_path
	raise ValueError(f"Unable to determine met input path for repo {repo} site {site}")

def to_seconds(x: int, units: str) -> int:
	"""
	Convert the specified value to seconds.
	"""
	if units == "seconds":
		return x
	elif units == "minutes":
		return x * SECONDS_PER_MINUTE
	elif units == "hours":
		return x * SECONDS_PER_HOUR
	elif units == "days":
		return x * SECONDS_PER_HOUR * HOURS_PER_DAY
	raise ValueError(f"Unknown time units '{units}'")

def get_date(x: int, units: str) -> datetime.datetime:
	"""
	Parse a datetime object from a netcdf date variable value.
	"""
	_UNITS_REGEX = r"([^ ]+) since (\d{4})-(\d{2})-(\d{2}) (\d{2}):(\d{2}):(\d{2})"
	pattern = re.compile(_UNITS_REGEX)
	match = re.match(pattern, units)
	if match is None:
		raise ValueError(f"Unable to parse time units {units}")

	increment = units.split(" ")[0].lower()
	baseline = datetime.datetime(
		year = int(match.group(2)),
		month = int(match.group(3)),
		day = int(match.group(4)),
		hour = int(match.group(5)),
		minute = int(match.group(6)),
		second = int(match.group(7))
	)

	seconds = to_seconds(x, increment)
	return baseline + datetime.timedelta(seconds = seconds)

def get_site_weight(repo: str, site: str) -> int:
	"""
	Return the relative weighting of a site in a repository. This weighting
	represents the amount of time required to run the site, relative to other
	sites. This implementation of the function uses the simulation length (in
	years), which may be determined by opening the input .nc file.

	@param repo: Path to the lpj-guess repository.
	@param site: Name of the site.
	"""
	met_path = get_site_met(repo, site)
	with open_netcdf(met_path) as met:
		if VAR_TIME in met.variables:
			time = met.variables[VAR_TIME]
			end = get_date(time[len(time) - 1], time.units)
			start = get_date(time[0], time.units)
			seconds = (end - start).total_seconds()
			log_diagnostic(f"Site '{site}' in repo '{repo}' has weight of {seconds}")
			return seconds
	raise ValueError(f"Unable to determine weighting for site {site} in repo {repo}")

def build_repos(repos: list[str]):
	"""
	Build the model in each specified repository.

	@param repos: List of lpj-guess repository paths.
	"""
	log_information("Building...")
	builder = JobManager()
	for repo in repos:
		builder.add_job(GuessBuilder(repo))

	set_show_progress(False)
	builder.run_parallel(opts.parallel)
	set_show_progress(opts.report_progress)

def run_sites(repos: list[str], sites: list[str]):
	"""
	Run the model for all sites in all repositories.

	@param repos: List of lpj-guess repository paths.
	@param sites: List of ozflux sites to run.
	"""
	job_manager = JobManager()
	log_information("Running...")
	for repo in repos:
		repo = os.path.abspath(repo)
		guess = get_guess(repo)
		for site in sites:
			ins = get_site_ins(repo, site)
			weight = get_site_weight(repo, site)
			job_manager.add_job(SiteRunner(ins, guess), weight)
	job_manager.run_parallel(opts.parallel)

def ozflux_path(repo: str) -> str:
	"""
	Return the path to the ozflux directory in the given repository.

	@param repo: Path to an lpj-guess repository.
	"""
	return os.path.join(repo, "benchmarks", "ozflux")

def get_site_path(repo: str, site: str) -> str:
	"""
	Return the path to the site in the given repository.

	@param repo: Path to an lpj-guess repository.
	@param site: Name of an ozflux site.
	"""
	return os.path.join(ozflux_path(repo), site)

def get_outputs_ins(repo: str) -> str:
	"""
	Return the path to the outputs.ins instruction file for the specified repo.

	@param repo: Path to an lpj-guess repository.
	"""
	return os.path.join(ozflux_path(repo), _OUTPUTS_INS)

def get_site_ins(repo: str, site: str) -> str:
	"""
	Return the path to the site-level instruction file.

	@param repo: Path to an lpj-guess repository.
	@param site: Name of an ozflux site.
	"""
	return os.path.join(get_site_path(repo, site), f"{site}.ins")

def get_enabled_outputs(repo: str) -> tuple[str, list[str]]:
	"""
	Get the list of outputs enabled for the specified repository.

	@param repo: Path to an lpj-guess repository.

	Returns a tuple of (output path, list of enabled outputs).
	"""
	ins = get_outputs_ins(repo)
	file_pattern = re.compile(_OUTFILE_REGEX)
	dir_pattern = re.compile(_OUTDIR_REGEX)
	outputs: list[str] = []
	out_path: str = None
	with open(ins, "r") as file:
		for line in file:#.readlines():
			match = re.match(file_pattern, line)
			if match is not None:
				outputs.append(match.group(1))
			match = re.match(dir_pattern, line)
			if match is not None:
				out_path = match.group(1)
	if out_path is None:
		raise ValueError(f"Unknown output path for {repo}")
	return (out_path, outputs)

def concat_file(inpath: str, outpath: str, header: bool):
	"""
	Concatenate the contents of infile to outfile.

	@param infile: Input file path.
	@param outfile: Output file path.
	@param header: True to copy file header. False otherwise.
	"""
	log_debug(f"Concatenating '{inpath}' to '{outpath}'...")
	with open(inpath, "rb") as infile:
		if not header:
			infile.readline()
		with open(outpath, "ab") as outfile:
			shutil.copyfileobj(infile, outfile)

def copy_outputs_repo(repo: str, sites: list[str], out: str):
	"""
	Copy all outputs of the specified sites in the given repo into the specified
	output directory.

	@param repo: Path to an lpj-guess repository.
	@param sites: List of sites for which outputs will be copied.
	@param out: Output directory.
	"""
	(outputs_path, outputs) = get_enabled_outputs(repo)
	i = 0
	for site in sites:
		site_path = get_site_path(repo, site)
		site_out = os.path.join(site_path, outputs_path)
		for output in outputs:
			infile = os.path.join(site_out, output)
			outfile = os.path.join(out, os.path.basename(output))
			concat_file(infile, outfile, i == 0)
		i += 1

def copy_outputs(repos: list[str], sites: list[str], out_dir: str):
	"""
	Concatenate all outputs from all sites for each specified repository into
	the specified output directory.

	@param repos: List of paths to lpj-guess repositories.
	@param sites: List of sites for which outputs will be copied.
	@param out_dir: Output directory.
	"""
	out_dir = os.path.abspath(out_dir)
	log_information("Copying outputs...")
	for repo in repos:
		repo_name = os.path.basename(repo.strip(os.path.sep))
		log_diagnostic(f"Copying outputs from repository '{repo_name}'")

		# Delete output directory if it already exists, then create it anew.
		repo_out = os.path.join(out_dir, repo_name)
		if os.path.exists(repo_out):
			shutil.rmtree(repo_out)
		os.makedirs(repo_out)

		copy_outputs_repo(repo, sites, repo_out)

def main(opts: Options):
	"""
	Main function.

	@param opts: Parsed CLI options provided by the user.
	"""
	if opts.build:
		build_repos(opts.repos)

	if opts.run:
		run_sites(opts.repos, opts.sites)

	if opts.copy:
		copy_outputs(opts.repos, opts.sites, opts.out_dir)

if __name__ == "__main__":
	# Parse CLI args
	opts = parse_args(argv)

	set_log_level(opts.log_level)
	set_show_progress(opts.report_progress)

	try:
		# Actual logic is in main().
		main(opts)
	except BaseException as error:
		# Basic error handling.
		log_error(traceback.format_exc())
		exit(1)
